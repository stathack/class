{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATX-DAT-2 | Demo 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim (http://radimrehurek.com/gensim) is a library of language processing tools focused on latent variable models of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_extraction\n",
    "from gensim import matutils, models\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is about sentiments on Amazon reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "sentiments = []\n",
    "\n",
    "with open(os.path.join('..', 'datasets', 'amazon-reviews.txt')) as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        review, sentiment = line.split('\\t')\n",
    "        sentiment = np.nan if sentiment == '' else int(sentiment)\n",
    "\n",
    "        reviews.append(review.lower())\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "df = pd.DataFrame({'review': reviews, 'sentiment': sentiments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i try not to adjust the volume setting to avoi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good case, excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i thought motorola made reliable products!.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery for motorola razr.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  i try not to adjust the volume setting to avoi...        NaN\n",
       "1  so there is no way for me to plug it in here i...        0.0\n",
       "2                        good case, excellent value.        1.0\n",
       "3        i thought motorola made reliable products!.        NaN\n",
       "4                         battery for motorola razr.        NaN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True) # Let's drop the NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good case, excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>great for the jawbone.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the mic is great.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  sentiment\n",
       "1   so there is no way for me to plug it in here i...        0.0\n",
       "2                         good case, excellent value.        1.0\n",
       "5                              great for the jawbone.        1.0\n",
       "10  tied to charger for conversations lasting more...        0.0\n",
       "11                                  the mic is great.        1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first translate a set of documents (articles) into a matrix representation with a row per document and a column per feature (word or n-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fify',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = feature_extraction.text.CountVectorizer(stop_words = 'english')\n",
    "\n",
    "vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = vectorizer.fit_transform(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's now build a mapping of numerical ID to word\n",
    "\n",
    "id2word = dict(enumerate(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8383"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to learn which columns are correlated (i.e., likely to come from the same topic).  This is the word distribution.  We can also determine what topics are in each document, the topic distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we convert our word-matrix into gensim's format\n",
    "\n",
    "corpus = matutils.Sparse2Corpus(documents, documents_columns = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Check https://radimrehurek.com/gensim/matutils as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.matutils.Sparse2Corpus at 0x11b4160d0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Check https://radimrehurek.com/gensim/models/ldamodel as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Then we fit an LDA model\n",
    "model=models.ldamodel.LdaModel(corpus = corpus, num_topics = 10, id2word = id2word, passes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we need to explicitly specify the number of topic we want the model to uncover.  This is a critical parameter, but there isn't much guidance on how to choose it.  Try to use domain expertise where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x118c9f690>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to assess the goodness of fit for our model.  Like other unsupervised learning techniques, our validation techniques are mostly about interpretation.\n",
    "\n",
    "Use the following questions to guide you:\n",
    "- Did we learn reasonable topics?\n",
    "- Do the words that make up a topic make sense?\n",
    "- Is this topic helpful towards our goal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19,\n",
       "  u'0.029*phone + 0.015*great + 0.015*belt + 0.010*make + 0.010*think + 0.010*plan + 0.010*trying + 0.010*plus + 0.010*sure + 0.010*disappointing'),\n",
       " (17,\n",
       "  u'0.041*phone + 0.026*does + 0.022*work + 0.014*charge + 0.013*cool + 0.010*product + 0.010*better + 0.010*said + 0.007*worked + 0.007*time'),\n",
       " (3,\n",
       "  u'0.088*battery + 0.028*life + 0.026*great + 0.022*long + 0.015*works + 0.012*case + 0.012*don + 0.009*lot + 0.007*using + 0.006*phone'),\n",
       " (6,\n",
       "  u'0.037*phone + 0.032*piece + 0.020*junk + 0.019*love + 0.016*disappointment + 0.016*device + 0.014*just + 0.012*screen + 0.012*want + 0.008*features'),\n",
       " (8,\n",
       "  u'0.075*phone + 0.042*great + 0.023*case + 0.020*doesn + 0.016*charger + 0.012*works + 0.011*pleased + 0.011*excellent + 0.010*using + 0.010*work'),\n",
       " (12,\n",
       "  u'0.027*bad + 0.020*new + 0.013*car + 0.013*like + 0.013*love + 0.012*better + 0.011*pretty + 0.010*ear + 0.010*software + 0.010*work'),\n",
       " (9,\n",
       "  u'0.043*waste + 0.034*money + 0.030*phone + 0.016*cell + 0.016*product + 0.015*don + 0.013*working + 0.013*days + 0.010*good + 0.010*volume'),\n",
       " (5,\n",
       "  u'0.033*phone + 0.021*worked + 0.015*jabra + 0.013*sound + 0.012*use + 0.011*battery + 0.011*ear + 0.011*clarity + 0.011*beep + 0.007*really'),\n",
       " (0,\n",
       "  u'0.039*good + 0.027*phone + 0.023*item + 0.023*nice + 0.022*case + 0.012*battery + 0.011*great + 0.010*does + 0.010*looks + 0.010*quality'),\n",
       " (10,\n",
       "  u'0.067*ve + 0.053*phone + 0.018*worst + 0.014*best + 0.010*months + 0.009*great + 0.009*reception + 0.009*completely + 0.009*battery + 0.009*clip')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some topics will be clearer than others.  The following topics represent clear concepts:\n",
    "- Cooking and Recipes: 0.009 \\* cup + 0.009 \\* recipe + 0.007 \\* make + 0.007 \\* food + 0.006 \\* sugar\n",
    "- Cooking and recipes: 0.013 \\* butter + 0.010 \\* baking + 0.010 \\* dough + 0.009 \\* cup + 0.009 \\* sugar\n",
    "- Fashion and Style: 0.013 \\* fashion + 0.006 \\* like + 0.006 \\* dress + 0.005 \\* style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "(0, u'0.064*buy + 0.021*don + 0.016*pay + 0.014*phone + 0.014*card + 0.013*good + 0.012*purchase + 0.011*seller + 0.011*sony + 0.010*piece + 0.010*value + 0.009*product + 0.008*junk + 0.008*decent + 0.008*sure + 0.007*try + 0.007*amazon + 0.007*pleased + 0.007*item + 0.007*ericsson + 0.006*pictures + 0.006*sim + 0.006*need + 0.006*thanks + 0.006*thought + 0.006*memory + 0.006*forget + 0.006*return + 0.005*care + 0.005*calling + 0.005*sucks + 0.005*tell + 0.005*100 + 0.005*sold + 0.005*plan + 0.004*definitely + 0.004*thinking + 0.004*hope + 0.004*data + 0.004*impossible + 0.004*satisfied + 0.004*loved + 0.004*technology + 0.004*crap + 0.004*kit + 0.004*fault + 0.004*research + 0.003*available + 0.003*tone + 0.003*expensive + 0.003*cingular + 0.003*plastic + 0.003*contacts + 0.003*friend + 0.003*skype + 0.003*earbuds + 0.003*breaks + 0.003*sd + 0.003*rating + 0.003*band + 0.003*ones + 0.003*ringtone + 0.003*thats + 0.003*run + 0.003*process + 0.003*50 + 0.003*ordering + 0.003*clips + 0.003*times + 0.003*lots + 0.003*cables + 0.003*told + 0.003*unlocked + 0.002*complete + 0.002*blinking + 0.002*en + 0.002*allow + 0.002*speak + 0.002*upgraded + 0.002*wire + 0.002*page + 0.002*functionality + 0.002*store + 0.002*songs + 0.002*record + 0.002*sending + 0.002*overall + 0.002*highest + 0.002*new + 0.002*samsung + 0.002*mobile + 0.002*nokia + 0.002*echo + 0.002*air + 0.002*early + 0.002*communication + 0.002*despite + 0.002*powered + 0.002*heck + 0.002*problem')\n",
      "()\n",
      "Topic: 1\n",
      "(1, u'0.034*bought + 0.031*service + 0.029*phone + 0.016*problems + 0.013*amazon + 0.013*customer + 0.012*button + 0.012*month + 0.012*worst + 0.012*happy + 0.011*verizon + 0.011*hard + 0.011*samsung + 0.010*product + 0.010*read + 0.009*sprint + 0.009*support + 0.009*ve + 0.008*called + 0.008*bad + 0.008*company + 0.007*exactly + 0.007*returned + 0.007*press + 0.007*replace + 0.006*told + 0.006*reviews + 0.006*couldn + 0.006*20 + 0.006*motorola + 0.006*tech + 0.005*issue + 0.005*numbers + 0.005*turned + 0.005*pairing + 0.005*yes + 0.005*refund + 0.005*annoying + 0.005*hearing + 0.005*line + 0.005*send + 0.005*nokia + 0.004*problem + 0.004*v3 + 0.004*phones + 0.004*contacted + 0.004*nextel + 0.004*time + 0.004*said + 0.004*wasn + 0.004*exchange + 0.004*cingular + 0.004*stylus + 0.004*razr + 0.004*used + 0.004*took + 0.004*online + 0.004*warranty + 0.004*kind + 0.004*item + 0.003*having + 0.003*os + 0.003*surprised + 0.003*return + 0.003*just + 0.003*book + 0.003*thank + 0.003*figure + 0.003*think + 0.003*store + 0.003*unfortunately + 0.003*text + 0.003*glad + 0.003*purchase + 0.003*ended + 0.003*options + 0.003*mind + 0.003*body + 0.003*menu + 0.003*wireless + 0.003*camera + 0.003*trouble + 0.003*owned + 0.003*wait + 0.003*tried + 0.003*search + 0.003*dollars + 0.002*huge + 0.002*website + 0.002*chocolate + 0.002*mode + 0.002*performance + 0.002*ordered + 0.002*display + 0.002*period + 0.002*tones + 0.002*losing + 0.002*additional + 0.002*drive + 0.002*glove')\n",
      "()\n",
      "Topic: 2\n",
      "(2, u'0.034*phone + 0.023*nice + 0.021*recommend + 0.019*case + 0.017*looks + 0.016*fit + 0.015*light + 0.015*ear + 0.014*big + 0.014*like + 0.013*good + 0.013*right + 0.013*little + 0.012*features + 0.012*thing + 0.011*fits + 0.011*product + 0.010*cheap + 0.010*buttons + 0.010*cool + 0.010*blue + 0.009*comes + 0.009*perfectly + 0.009*cord + 0.008*really + 0.007*terrible + 0.007*screen + 0.007*power + 0.007*highly + 0.006*fact + 0.006*user + 0.006*color + 0.006*got + 0.006*size + 0.006*dont + 0.006*cellphone + 0.005*advertised + 0.005*pretty + 0.005*wouldn + 0.005*leather + 0.005*tooth + 0.005*small + 0.005*wrong + 0.005*plastic + 0.005*ears + 0.005*instructions + 0.004*thought + 0.004*hand + 0.004*uncomfortable + 0.004*cut + 0.004*supposed + 0.004*decided + 0.004*cost + 0.004*item + 0.004*reason + 0.004*pearl + 0.004*unit + 0.004*love + 0.004*earpiece + 0.004*doesn + 0.004*clearly + 0.004*friendly + 0.004*bright + 0.003*came + 0.003*business + 0.003*piece + 0.003*bulky + 0.003*maybe + 0.003*main + 0.003*video + 0.003*makes + 0.003*complaint + 0.003*short + 0.003*super + 0.003*keeps + 0.003*carrier + 0.003*overall + 0.003*touch + 0.003*reset + 0.003*try + 0.003*white + 0.002*possible + 0.002*push + 0.002*large + 0.002*having + 0.002*awful + 0.002*running + 0.002*heavy + 0.002*getting + 0.002*protection + 0.002*described + 0.002*transmitter + 0.002*way + 0.002*pros + 0.002*accessories + 0.002*box + 0.002*wanted + 0.002*glasses + 0.002*camera + 0.002*pieces')\n",
      "()\n",
      "Topic: 3\n",
      "(3, u'0.069*phone + 0.066*battery + 0.027*cell + 0.017*new + 0.016*old + 0.014*day + 0.013*treo + 0.013*life + 0.012*bought + 0.012*original + 0.011*replacement + 0.011*blackberry + 0.010*nokia + 0.010*motorola + 0.009*case + 0.009*come + 0.009*palm + 0.009*charging + 0.009*phones + 0.008*perfect + 0.008*clip + 0.008*long + 0.007*disappointed + 0.007*razr + 0.007*used + 0.007*came + 0.007*let + 0.006*650 + 0.006*ok + 0.006*experience + 0.006*belt + 0.006*did + 0.005*years + 0.005*week + 0.005*like + 0.005*use + 0.005*review + 0.005*thing + 0.005*know + 0.005*holster + 0.005*radio + 0.005*broke + 0.004*says + 0.004*makes + 0.004*longer + 0.004*hours + 0.004*constantly + 0.004*wife + 0.004*kept + 0.004*pda + 0.004*course + 0.004*needed + 0.004*getting + 0.004*level + 0.003*received + 0.003*access + 0.003*using + 0.003*want + 0.003*mobile + 0.003*impressed + 0.003*bad + 0.003*sync + 0.003*real + 0.003*useful + 0.003*taking + 0.003*days + 0.003*h700 + 0.003*start + 0.003*returning + 0.003*happened + 0.003*larger + 0.003*stuck + 0.002*snap + 0.002*said + 0.002*files + 0.002*extended + 0.002*wouldn + 0.002*particular + 0.002*tried + 0.002*30 + 0.002*hold + 0.002*worn + 0.002*directly + 0.002*item + 0.002*don + 0.002*recharge + 0.002*reasons + 0.002*doing + 0.002*message + 0.002*minor + 0.002*charged + 0.002*basically + 0.002*replacing + 0.002*storage + 0.002*ripped + 0.002*provide + 0.002*worked + 0.002*died + 0.002*older + 0.002*ends')\n",
      "()\n",
      "Topic: 4\n",
      "(4, u'0.050*phone + 0.044*good + 0.023*got + 0.016*purchased + 0.015*love + 0.014*months + 0.014*working + 0.012*year + 0.012*far + 0.011*ve + 0.010*headset + 0.009*ago + 0.009*case + 0.008*does + 0.008*mobile + 0.008*phones + 0.008*cingular + 0.007*product + 0.007*new + 0.007*half + 0.007*weeks + 0.007*pretty + 0.007*better + 0.007*looking + 0.007*price + 0.007*isn + 0.007*worked + 0.006*model + 0.006*did + 0.006*things + 0.006*number + 0.006*motorola + 0.006*look + 0.006*really + 0.006*job + 0.006*stopped + 0.005*jabra + 0.005*heard + 0.005*different + 0.005*iphone + 0.005*like + 0.005*going + 0.005*inside + 0.005*reception + 0.004*replaced + 0.004*store + 0.004*friends + 0.004*luck + 0.004*jawbone + 0.004*contract + 0.004*internet + 0.004*answer + 0.004*travel + 0.004*couple + 0.003*amazing + 0.003*previous + 0.003*recommended + 0.003*know + 0.003*lot + 0.003*00 + 0.003*wireless + 0.003*years + 0.003*immediately + 0.003*razr + 0.003*broke + 0.003*believe + 0.003*hour + 0.003*gave + 0.003*feel + 0.003*designed + 0.003*totally + 0.003*problems + 0.003*slim + 0.003*costs + 0.003*ordered + 0.003*people + 0.003*live + 0.003*past + 0.003*information + 0.003*reviews + 0.003*standby + 0.003*make + 0.003*sprint + 0.003*note + 0.003*durable + 0.002*negative + 0.002*cause + 0.002*site + 0.002*used + 0.002*command + 0.002*network + 0.002*unit + 0.002*minute + 0.002*razor + 0.002*area + 0.002*anymore + 0.002*match + 0.002*sell + 0.002*moto + 0.002*wind')\n",
      "()\n",
      "Topic: 5\n",
      "(5, u'0.044*quality + 0.037*sound + 0.036*use + 0.024*easy + 0.021*ear + 0.018*headset + 0.017*good + 0.017*excellent + 0.016*phone + 0.015*comfortable + 0.014*really + 0.012*design + 0.012*poor + 0.011*clear + 0.010*think + 0.010*voice + 0.010*speaker + 0.010*noise + 0.009*easily + 0.008*music + 0.008*wear + 0.008*like + 0.007*headphones + 0.007*set + 0.007*small + 0.006*volume + 0.006*extremely + 0.006*simple + 0.005*feature + 0.005*don + 0.005*make + 0.005*style + 0.005*ring + 0.005*type + 0.005*worse + 0.005*transfer + 0.004*audio + 0.004*mic + 0.004*clip + 0.004*dialing + 0.004*camera + 0.004*devices + 0.004*contact + 0.004*email + 0.004*looking + 0.004*head + 0.004*complaints + 0.004*using + 0.004*matter + 0.004*device + 0.004*stereo + 0.004*absolutely + 0.004*standard + 0.004*bad + 0.004*used + 0.003*bluetooth + 0.003*control + 0.003*allows + 0.003*speakerphone + 0.003*cheap + 0.003*fits + 0.003*liked + 0.003*sleek + 0.003*simply + 0.003*listening + 0.003*stick + 0.003*stand + 0.003*headphone + 0.003*piece + 0.003*microphone + 0.003*built + 0.003*keyboard + 0.003*stylish + 0.003*end + 0.003*carry + 0.003*comfort + 0.002*want + 0.002*bud + 0.002*pair + 0.002*actually + 0.002*outlook + 0.002*handset + 0.002*photo + 0.002*quiet + 0.002*product + 0.002*features + 0.002*feels + 0.002*sturdy + 0.002*necessary + 0.002*mistake + 0.002*speakers + 0.002*need + 0.002*difference + 0.002*hook + 0.002*flimsy + 0.002*keeping + 0.002*problem + 0.002*pouch + 0.002*hearing + 0.002*say')\n",
      "()\n",
      "Topic: 6\n",
      "(6, u'0.122*great + 0.067*works + 0.028*product + 0.028*phone + 0.023*better + 0.021*fine + 0.012*price + 0.011*just + 0.011*screen + 0.009*shipping + 0.009*reception + 0.009*deal + 0.009*horrible + 0.009*stars + 0.008*arrived + 0.008*expected + 0.008*gets + 0.007*little + 0.007*say + 0.007*needs + 0.007*fast + 0.007*quickly + 0.007*windows + 0.006*help + 0.006*signal + 0.006*case + 0.006*camera + 0.005*worked + 0.004*range + 0.004*bad + 0.004*antenna + 0.004*seen + 0.004*device + 0.004*ringtones + 0.004*house + 0.004*red + 0.004*perfect + 0.004*make + 0.004*bucks + 0.004*install + 0.003*think + 0.003*okay + 0.003*feet + 0.003*useless + 0.003*item + 0.003*placed + 0.003*caller + 0.003*shipped + 0.003*lost + 0.003*sounded + 0.003*3rd + 0.003*twice + 0.003*items + 0.003*wish + 0.003*tape + 0.003*overall + 0.003*protector + 0.003*solid + 0.003*headset + 0.003*inexpensive + 0.003*lack + 0.003*included + 0.003*star + 0.003*leave + 0.003*different + 0.003*lightweight + 0.003*metal + 0.003*weak + 0.003*improvement + 0.003*file + 0.003*external + 0.003*15 + 0.002*way + 0.002*models + 0.002*looking + 0.002*feel + 0.002*id + 0.002*wonderful + 0.002*sure + 0.002*spent + 0.002*son + 0.002*xp + 0.002*reliable + 0.002*certain + 0.002*aren + 0.002*unable + 0.002*t610 + 0.002*pink + 0.002*info + 0.002*average + 0.002*china + 0.002*rings + 0.002*lg + 0.002*ipod + 0.002*electronics + 0.002*need + 0.002*solution + 0.002*speed + 0.002*easier + 0.002*unfortunately')\n",
      "()\n",
      "Topic: 7\n",
      "(7, u'0.042*bluetooth + 0.041*headset + 0.024*best + 0.021*price + 0.017*ve + 0.015*problem + 0.013*motorola + 0.013*software + 0.011*tried + 0.011*plantronics + 0.010*buying + 0.010*headsets + 0.009*ll + 0.009*batteries + 0.009*using + 0.008*better + 0.008*phone + 0.008*unit + 0.008*sent + 0.008*new + 0.007*order + 0.007*ordered + 0.007*product + 0.007*far + 0.006*received + 0.006*owned + 0.006*used + 0.006*said + 0.006*paid + 0.005*talking + 0.005*people + 0.005*needed + 0.005*picture + 0.005*guess + 0.005*amazon + 0.004*brand + 0.004*issues + 0.004*days + 0.004*pc + 0.004*like + 0.004*quick + 0.004*plus + 0.004*phones + 0.004*point + 0.004*oem + 0.004*hear + 0.004*charges + 0.003*calendar + 0.003*market + 0.003*interface + 0.003*510 + 0.003*sure + 0.003*reviews + 0.003*low + 0.003*regular + 0.003*way + 0.003*h500 + 0.003*happy + 0.003*gone + 0.003*beat + 0.003*weight + 0.003*looked + 0.003*compared + 0.003*case + 0.003*expect + 0.003*especially + 0.003*beware + 0.003*razr + 0.003*mouth + 0.003*connector + 0.003*replacement + 0.003*couple + 0.003*check + 0.003*appears + 0.003*today + 0.003*package + 0.003*night + 0.003*know + 0.003*chargers + 0.002*buyer + 0.002*putting + 0.002*remove + 0.002*high + 0.002*voyager + 0.002*set + 0.002*mentioned + 0.002*return + 0.002*carrying + 0.002*loop + 0.002*uses + 0.002*years + 0.002*went + 0.002*fantastic + 0.002*removed + 0.002*lose + 0.002*having + 0.002*rate + 0.002*opinion + 0.002*reading + 0.002*pictures')\n",
      "()\n",
      "Topic: 8\n",
      "(8, u'0.054*phone + 0.045*just + 0.016*hear + 0.015*calls + 0.014*like + 0.012*use + 0.012*free + 0.009*time + 0.009*people + 0.008*don + 0.008*second + 0.008*volume + 0.008*times + 0.008*bit + 0.008*ear + 0.008*make + 0.007*stay + 0.007*want + 0.007*away + 0.007*loud + 0.007*little + 0.007*days + 0.007*hands + 0.007*10 + 0.007*right + 0.006*cover + 0.006*turn + 0.006*minutes + 0.006*static + 0.006*won + 0.006*went + 0.006*screen + 0.005*dropped + 0.005*does + 0.005*hold + 0.005*earpiece + 0.005*instead + 0.005*doesn + 0.005*place + 0.005*able + 0.005*trying + 0.005*lot + 0.005*end + 0.005*defective + 0.005*months + 0.004*didn + 0.004*low + 0.004*pocket + 0.004*way + 0.004*talk + 0.004*headset + 0.004*hate + 0.004*cell + 0.004*ve + 0.004*save + 0.004*say + 0.004*driving + 0.004*pretty + 0.004*bt + 0.004*left + 0.004*fine + 0.004*started + 0.004*wanted + 0.004*problem + 0.003*goes + 0.003*feel + 0.003*outside + 0.003*flip + 0.003*using + 0.003*normal + 0.003*thing + 0.003*fall + 0.003*mail + 0.003*person + 0.003*short + 0.003*scratches + 0.003*upgrade + 0.003*signal + 0.003*slow + 0.003*accessory + 0.003*usually + 0.003*bad + 0.003*need + 0.003*switch + 0.003*drop + 0.003*strong + 0.003*open + 0.003*avoid + 0.003*extra + 0.003*making + 0.003*listen + 0.003*button + 0.002*broken + 0.002*fell + 0.002*bars + 0.002*takes + 0.002*apart + 0.002*port + 0.002*sanyo + 0.002*road')\n",
      "()\n",
      "Topic: 9\n",
      "(9, u'0.060*work + 0.034*charger + 0.031*time + 0.026*does + 0.026*charge + 0.023*money + 0.018*doesn + 0.017*car + 0.017*did + 0.016*phone + 0.016*worth + 0.015*cable + 0.015*didn + 0.012*use + 0.012*don + 0.011*usb + 0.010*plug + 0.009*waste + 0.009*got + 0.008*mp3 + 0.007*hours + 0.007*quite + 0.007*fit + 0.006*device + 0.006*products + 0.006*charged + 0.006*home + 0.006*sounds + 0.005*awesome + 0.005*haven + 0.005*player + 0.005*computer + 0.005*long + 0.005*different + 0.005*tried + 0.005*ipod + 0.005*idea + 0.005*motorola + 0.004*poorly + 0.004*version + 0.004*like + 0.004*function + 0.004*background + 0.004*need + 0.004*good + 0.004*quot + 0.004*talk + 0.004*plugged + 0.004*connect + 0.004*camera + 0.004*husband + 0.004*given + 0.003*true + 0.003*item + 0.003*keys + 0.003*laptop + 0.003*cases + 0.003*adapter + 0.003*delivery + 0.003*phones + 0.003*damage + 0.003*hold + 0.003*wired + 0.003*properly + 0.003*wall + 0.003*promised + 0.003*loose + 0.003*came + 0.003*functions + 0.003*left + 0.003*stays + 0.003*jack + 0.003*want + 0.002*coming + 0.002*cost + 0.002*constant + 0.002*5mm + 0.002*received + 0.002*attached + 0.002*excited + 0.002*mini + 0.002*fully + 0.002*lg + 0.002*compatible + 0.002*perfect + 0.002*krzr + 0.002*number + 0.002*smartphone + 0.002*starting + 0.002*considering + 0.002*gift + 0.002*drops + 0.002*careful + 0.002*line + 0.002*hard + 0.002*load + 0.002*apparently + 0.002*tracfone + 0.002*vendor + 0.002*stock')\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "num_topics = 20\n",
    "n_words_per_topic = 100\n",
    "for ti, topic in enumerate(model.show_topics(num_words=n_words_per_topic, num_topics=num_topics)):\n",
    "    print(\"Topic: %d\" % (ti))\n",
    "    print (topic)    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.show_topics??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the body text\n",
    "sentences = df.review.map(lambda review: review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [i, try, not, to, adjust, the, volume, setting...\n",
       "1        [so, there, is, no, way, for, me, to, plug, it...\n",
       "2                         [good, case,, excellent, value.]\n",
       "3        [i, thought, motorola, made, reliable, product...\n",
       "4                          [battery, for, motorola, razr.]\n",
       "5                              [great, for, the, jawbone.]\n",
       "6        [when, i, got, this, item, it, was, larger, th...\n",
       "7        [(i, looked, for, one, that, specifically, sai...\n",
       "8        [the, first, time, it, was, turned, on, the, s...\n",
       "9        [in, some, programs, clicking, it, is, the, sa...\n",
       "10       [tied, to, charger, for, conversations, lastin...\n",
       "11                                  [the, mic, is, great.]\n",
       "12       [what, happened, was, that, i, only, had, like...\n",
       "13       [i, have, to, jiggle, the, plug, to, get, it, ...\n",
       "14       [i, bought, five, of, thes, for, less, than, f...\n",
       "                               ...                        \n",
       "14989                                  [not, spectacular.]\n",
       "14990    [because, leaving, it, in, my, ear, was, chanc...\n",
       "14991                        [nice, garbage....literally.]\n",
       "14992                              [connection, problems.]\n",
       "14993    [after, two, days, of, use,, one, of, the, aud...\n",
       "14994    [but, that, i, can, sell, it, and, make, my, m...\n",
       "14995                                   [what, warranty?.]\n",
       "14996    [like, i, said,, the, design, is, great.the, h...\n",
       "14997    [they, promised, that, they, are, reviewing, t...\n",
       "14998                  [found, one, here, thru, eforcity.]\n",
       "14999    [the, screen, on, my, phone, said, \"not, charg...\n",
       "15000    [this, is, my, 4th, samsung, cell, phone, with...\n",
       "15001                                    [great, company.]\n",
       "15002    [the, \"call\", and, \"hang-up\", keys, are, now, ...\n",
       "15003         [hopefully, the, kyocera, will, be, better!]\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.Word2Vec(sentences, size = 100, window = 5, min_count = 5, workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Word2Vec` has many arguments:\n",
    "- `size` represents how many concepts or topics we should use\n",
    "- `window` represents how many words surrounding a sentence we should use as our original feature\n",
    "- `min_count` is the number of times that context or word must appear\n",
    "- `workers` is the number of CPU cores to use to speed up model training\n",
    "\n",
    "(Check http://radimrehurek.com/gensim/models/word2vec as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x11c089d10>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most similar words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a `most_similar` function that helps find the words most similar to the one you queried.  This will return words that are most often used in the same context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('volume', 0.9977969527244568),\n",
       " ('ear.', 0.9967939853668213),\n",
       " ('buttons', 0.9965591430664062),\n",
       " ('comfortable', 0.9965134263038635),\n",
       " ('video', 0.9961884021759033),\n",
       " ('side', 0.9961011409759521),\n",
       " ('loud,', 0.9959816932678223),\n",
       " ('ear,', 0.9959695339202881),\n",
       " ('quiet', 0.9959319829940796),\n",
       " ('button', 0.995930552482605)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive = ['ear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-3b696919d169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-3b696919d169>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(sentence)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-3b696919d169>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(word)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/chrisconnell/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n\u001b[0;32m--> 906\u001b[0;31m                                      key=itemgetter(1))]\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentences = list(map(lambda sentence: list(filter(lambda word: word in vectorizer.get_feature_names(), sentence)), sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [i, try, not, to, adjust, the, volume, setting...\n",
       "1        [so, there, is, no, way, for, me, to, plug, it...\n",
       "2                         [good, case,, excellent, value.]\n",
       "3        [i, thought, motorola, made, reliable, product...\n",
       "4                          [battery, for, motorola, razr.]\n",
       "5                              [great, for, the, jawbone.]\n",
       "6        [when, i, got, this, item, it, was, larger, th...\n",
       "7        [(i, looked, for, one, that, specifically, sai...\n",
       "8        [the, first, time, it, was, turned, on, the, s...\n",
       "9        [in, some, programs, clicking, it, is, the, sa...\n",
       "10       [tied, to, charger, for, conversations, lastin...\n",
       "11                                  [the, mic, is, great.]\n",
       "12       [what, happened, was, that, i, only, had, like...\n",
       "13       [i, have, to, jiggle, the, plug, to, get, it, ...\n",
       "14       [i, bought, five, of, thes, for, less, than, f...\n",
       "                               ...                        \n",
       "14989                                  [not, spectacular.]\n",
       "14990    [because, leaving, it, in, my, ear, was, chanc...\n",
       "14991                        [nice, garbage....literally.]\n",
       "14992                              [connection, problems.]\n",
       "14993    [after, two, days, of, use,, one, of, the, aud...\n",
       "14994    [but, that, i, can, sell, it, and, make, my, m...\n",
       "14995                                   [what, warranty?.]\n",
       "14996    [like, i, said,, the, design, is, great.the, h...\n",
       "14997    [they, promised, that, they, are, reviewing, t...\n",
       "14998                  [found, one, here, thru, eforcity.]\n",
       "14999    [the, screen, on, my, phone, said, \"not, charg...\n",
       "15000    [this, is, my, 4th, samsung, cell, phone, with...\n",
       "15001                                    [great, company.]\n",
       "15002    [the, \"call\", and, \"hang-up\", keys, are, now, ...\n",
       "15003         [hopefully, the, kyocera, will, be, better!]\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.Word2Vec(sentences, size = 100, window = 5, min_count = 5, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phones', 0.22747108340263367),\n",
       " ('piece', 0.22566647827625275),\n",
       " ('battery', 0.19638335704803467),\n",
       " ('does', 0.18861348927021027),\n",
       " ('hard', 0.18570223450660706),\n",
       " ('cheap', 0.18267108500003815),\n",
       " ('item', 0.17193655669689178),\n",
       " ('days', 0.17131055891513824),\n",
       " ('fits', 0.16991697251796722),\n",
       " ('broke', 0.16979514062404633)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive = ['phone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named detectEnglish",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-24c77eea6a37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdetectEnglish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdetectEnglish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnglish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chris'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named detectEnglish"
     ]
    }
   ],
   "source": [
    "import detectEnglish\n",
    "detectEnglish.isEnglish('chris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chris\n",
      "\tParent: lose\n",
      "\tPhrase type: nsubjpass\n",
      "\tKnown entity type: PERSON\n",
      "\tLemma: chris\n",
      "is\n",
      "\tParent: lose\n",
      "\tPhrase type: auxpass\n",
      "\tKnown entity type: n/a\n",
      "\tLemma: be\n",
      "lost\n",
      "\tParent: lose\n",
      "\tPhrase type: ROOT\n",
      "\tKnown entity type: n/a\n",
      "\tLemma: lose\n"
     ]
    }
   ],
   "source": [
    "from spacy.en import English\n",
    "nlp_toolkit = English()\n",
    "\n",
    "parsed = nlp_toolkit(u'Chris is lost')\n",
    "\n",
    "for (i, word) in enumerate(parsed): \n",
    "    print word\n",
    "    print \"\\tParent: {}\".format(word.head.lemma_)\n",
    "    print \"\\tPhrase type: {}\".format(word.dep_)\n",
    "    print \"\\tKnown entity type: {}\".format(word.ent_type_ if word.ent_type_ else 'n/a')\n",
    "    print \"\\tLemma: {}\".format(word.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
